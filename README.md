# ğŸš€ Form Correctness Detection Using Pose Estimation

This project implements a complete **exercise form correctness detection system** using **MediaPipe Pose Estimation** and **rule-based geometric analysis**.  
It detects body keypoints from video, computes joint angles and alignment, and produces:

- ğŸ¥ **Annotated exercise videos** with real-time feedback  
- ğŸ“Š **Frame-wise CSV metrics** for detailed quantitative analysis  

This project was developed as part of the **Smartan.AI Computer Vision Internship Task**.

---

## ğŸ¥ Demo Videos

- **Explantion Video Pitch**
  https://drive.google.com/file/d/1sx_qQK093Vd7u7DH1GVarRlfffR1mv66/view?usp=sharing
  
- **Bicep Curl (Annotated)**  
  This Video present in out folder

- **Lateral Raise (Annotated)**  
  This Video present in out folder

- **Squat (Annotated)**  
  This Video present in out folder


## âš ï¸ Environment & Execution Note (Important)

This project was executed in **Google Colab** because:

- âŒ Local Python environments had **version conflicts** with MediaPipe  
- âŒ MediaPipe redistributable binaries were **not compatible** with the local OS and Python version  
- âœ… Google Colab provides a **stable MediaPipe setup**, consistent Python versions, and smooth execution  

Therefore, all command examples in this repository use **Colab-style syntax** (`!python`, `%cd`, etc.).  
The codebase itself remains compatible with standard Python environments.

---

## ğŸš€ Key Features

- âœ” Human pose estimation using **MediaPipe Pose**
- âœ” Joint angle computation (elbow, shoulder, knee, back tilt)
- âœ” Symmetry and wristâ€“shoulder alignment checks
- âœ” Rule-based exercise correctness evaluation
- âœ” Real-time skeleton overlay and visual feedback
- âœ” Frame-wise CSV metrics generation
- âœ” Modular and extensible code architecture
- âœ” ğŸ“Š **MLflow experiment tracking support (Bonus)**

---

## ğŸ“ Project Structure

```
Form-Correctness-Detection-Using-Pose-Estimation/
â”‚â”€â”€ src/
â”‚    â”œâ”€â”€ pose_detector.py        # MediaPipe pose extraction
â”‚    â”œâ”€â”€ form_rules.py           # Angle calculations & rule logic
â”‚    â”œâ”€â”€ smoothing.py            # Noise reduction utilities
â”‚    â”œâ”€â”€ run_video.py            # End-to-end pipeline
â”‚
â”‚â”€â”€ sample_videos/
â”‚    â”œâ”€â”€ Bicep Curl.mp4
â”‚    â”œâ”€â”€ Lateral raise.mp4
â”‚    â”œâ”€â”€ Squat.mp4
â”‚
â”‚â”€â”€ out/
â”‚    â”œâ”€â”€ annotated_bicep.mp4
â”‚    â”œâ”€â”€ annotated_lateral.mp4
â”‚    â”œâ”€â”€ annotated_squat.mp4
â”‚    â”œâ”€â”€ metrics_bicep.csv
â”‚    â”œâ”€â”€ metrics_lateral.csv
â”‚    â”œâ”€â”€ metrics_squat.csv
â”‚
â”‚â”€â”€ mlflow_outputs/
â”‚    â”œâ”€â”€ videos/
â”‚    â””â”€â”€ csv/
â”‚
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚â”€â”€ REPORT.pdf
```

---

## ğŸ›  Installation

Install dependencies using:

```bash
pip install -r requirements.txt
```

### ğŸ“¦ Main Dependencies
- mediapipe  
- opencv-python-headless  
- numpy  
- pandas  
- scipy  
- tqdm  
- mlflow (optional)

---

## â–¶ï¸ How to Run (Google Colab)

Navigate to the project directory:

```bash
%cd /content/Form-Correctness-Detection-Using-Pose-Estimation
```

---

### ğŸ¯ Bicep Curl Analysis

```bash
!python -m src.run_video \
  --input "sample_videos/Bicep Curl.mp4" \
  --output "out/annotated_bicep.mp4" \
  --csv "out/metrics_bicep.csv"
```

---

### ğŸ¯ Lateral Raise Analysis

```bash
!python -m src.run_video \
  --input "sample_videos/Lateral raise.mp4" \
  --output "out/annotated_lateral.mp4" \
  --csv "out/metrics_lateral.csv"
```

---

### ğŸ¯ Squat Analysis

```bash
!python -m src.run_video \
  --input "sample_videos/Squat.mp4" \
  --output "out/annotated_squat.mp4" \
  --csv "out/metrics_squat.csv"
```

---

## ğŸ“Š MLflow Experiment Tracking (Bonus)

MLflow integration is included as an **optional enhancement** to track experiments, metrics, and outputs.

### ğŸš€ Run Squat Analysis with MLflow Enabled

```bash
!python -m src.run_video \
  --input "sample_videos/Squat.mp4" \
  --output "out/annotated_squat_mlflow.mp4" \
  --csv "out/metrics_squat_mlflow.csv" \
  --mlflow \
  --mlflow-experiment "Form-Correctness-Detection"
```

### ğŸ“ˆ What MLflow Logs
- ğŸ”¹ Input parameters (video name, FPS, frame count)
- ğŸ”¹ Statistical metrics (mean, min, max angles)
- ğŸ”¹ Artifacts (CSV files, annotated sample frames)

MLflow uses a **local SQLite backend**, which is suitable for Google Colab execution.

---

## ğŸ“Š Outputs

### ğŸ¥ Annotated Videos

All annotated videos are stored in:

```
out/annotated_*.mp4
```

Each video includes:
- Pose skeleton overlay  
- Live joint angle visualization  
- Rule-based correctness feedback (`OK / BAD`)  

---

### ğŸ“ˆ CSV Metrics

Each exercise generates a CSV file containing frame-wise metrics such as:
- Elbow angle  
- Shoulder alignment  
- Back tilt  
- Knee angle (squat)  
- Correctness flags  

Example:

```
frame, elbow_angle, back_tilt, is_correct
0, 45.6, 3.1, True
```

---

## ğŸ§  Posture Rules Implemented

### ğŸ’ª Bicep Curl
- Elbow angle remains within a valid range  
- Shoulder remains stable  
- Wrist stays aligned with the elbow  

### ğŸ‹ï¸ Lateral Raise
- Wristâ€“Elbowâ€“Shoulder alignment maintained  
- Symmetric arm raise  
- Avoid shoulder shrugging  

### ğŸ¦µ Squat
- Knee angle reaches sufficient depth  
- Back tilt remains within safe limits  
- Knees track over toes  

Detailed rule logic and thresholds are documented in **REPORT.pdf**.

---

## ğŸ“˜ Project Report

The file `REPORT.pdf` contains:
- System pipeline explanation
- Mathematical derivation of joint angles
- Rule design and thresholds
- Noise handling strategies
- Multi-person handling approach
- Challenges faced and future scope

---

## ğŸš€ Future Improvements

- Automatic repetition counting  
- ML-based exercise quality scoring  
- Kalman filtering for smoother keypoints  
- Support for additional exercises  
- Web or mobile deployment  

---

## ğŸ‘¤ Author

**Yogesh Kharb**  
Computer Vision Internship Candidate  
GitHub: https://github.com/Yogeshkharb111

---

â­ If you find this project useful, feel free to star the repository!
